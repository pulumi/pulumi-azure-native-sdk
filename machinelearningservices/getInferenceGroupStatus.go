// Code generated by the Pulumi SDK Generator DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package machinelearningservices

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi-azure-native-sdk/v2/utilities"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// Uses Azure REST API version 2023-08-01-preview.
//
// Other available API versions: 2024-01-01-preview, 2024-04-01-preview, 2024-10-01-preview, 2025-01-01-preview.
func GetInferenceGroupStatus(ctx *pulumi.Context, args *GetInferenceGroupStatusArgs, opts ...pulumi.InvokeOption) (*GetInferenceGroupStatusResult, error) {
	opts = utilities.PkgInvokeDefaultOpts(opts)
	var rv GetInferenceGroupStatusResult
	err := ctx.Invoke("azure-native:machinelearningservices:getInferenceGroupStatus", args, &rv, opts...)
	if err != nil {
		return nil, err
	}
	return rv.Defaults(), nil
}

type GetInferenceGroupStatusArgs struct {
	// InferenceGroup name.
	GroupName string `pulumi:"groupName"`
	// InferencePool name.
	PoolName string `pulumi:"poolName"`
	// The name of the resource group. The name is case insensitive.
	ResourceGroupName string `pulumi:"resourceGroupName"`
	// Name of Azure Machine Learning workspace.
	WorkspaceName string `pulumi:"workspaceName"`
}

type GetInferenceGroupStatusResult struct {
	// Gets or sets the actual capacity info for the group.
	ActualCapacityInfo *ActualCapacityInfoResponse `pulumi:"actualCapacityInfo"`
	// Gets or sets capacity used from the pool's reserved capacity.
	BonusExtraCapacity *int `pulumi:"bonusExtraCapacity"`
	// Gets or sets the actual number of endpoints in the group.
	EndpointCount *int `pulumi:"endpointCount"`
	// Gets or sets the request number of instances for the group.
	RequestedCapacity *int `pulumi:"requestedCapacity"`
}

// Defaults sets the appropriate defaults for GetInferenceGroupStatusResult
func (val *GetInferenceGroupStatusResult) Defaults() *GetInferenceGroupStatusResult {
	if val == nil {
		return nil
	}
	tmp := *val
	tmp.ActualCapacityInfo = tmp.ActualCapacityInfo.Defaults()

	if tmp.BonusExtraCapacity == nil {
		bonusExtraCapacity_ := 0
		tmp.BonusExtraCapacity = &bonusExtraCapacity_
	}
	if tmp.EndpointCount == nil {
		endpointCount_ := 0
		tmp.EndpointCount = &endpointCount_
	}
	if tmp.RequestedCapacity == nil {
		requestedCapacity_ := 0
		tmp.RequestedCapacity = &requestedCapacity_
	}
	return &tmp
}
func GetInferenceGroupStatusOutput(ctx *pulumi.Context, args GetInferenceGroupStatusOutputArgs, opts ...pulumi.InvokeOption) GetInferenceGroupStatusResultOutput {
	return pulumi.ToOutputWithContext(ctx.Context(), args).
		ApplyT(func(v interface{}) (GetInferenceGroupStatusResultOutput, error) {
			args := v.(GetInferenceGroupStatusArgs)
			options := pulumi.InvokeOutputOptions{InvokeOptions: utilities.PkgInvokeDefaultOpts(opts)}
			return ctx.InvokeOutput("azure-native:machinelearningservices:getInferenceGroupStatus", args, GetInferenceGroupStatusResultOutput{}, options).(GetInferenceGroupStatusResultOutput), nil
		}).(GetInferenceGroupStatusResultOutput)
}

type GetInferenceGroupStatusOutputArgs struct {
	// InferenceGroup name.
	GroupName pulumi.StringInput `pulumi:"groupName"`
	// InferencePool name.
	PoolName pulumi.StringInput `pulumi:"poolName"`
	// The name of the resource group. The name is case insensitive.
	ResourceGroupName pulumi.StringInput `pulumi:"resourceGroupName"`
	// Name of Azure Machine Learning workspace.
	WorkspaceName pulumi.StringInput `pulumi:"workspaceName"`
}

func (GetInferenceGroupStatusOutputArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GetInferenceGroupStatusArgs)(nil)).Elem()
}

type GetInferenceGroupStatusResultOutput struct{ *pulumi.OutputState }

func (GetInferenceGroupStatusResultOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GetInferenceGroupStatusResult)(nil)).Elem()
}

func (o GetInferenceGroupStatusResultOutput) ToGetInferenceGroupStatusResultOutput() GetInferenceGroupStatusResultOutput {
	return o
}

func (o GetInferenceGroupStatusResultOutput) ToGetInferenceGroupStatusResultOutputWithContext(ctx context.Context) GetInferenceGroupStatusResultOutput {
	return o
}

// Gets or sets the actual capacity info for the group.
func (o GetInferenceGroupStatusResultOutput) ActualCapacityInfo() ActualCapacityInfoResponsePtrOutput {
	return o.ApplyT(func(v GetInferenceGroupStatusResult) *ActualCapacityInfoResponse { return v.ActualCapacityInfo }).(ActualCapacityInfoResponsePtrOutput)
}

// Gets or sets capacity used from the pool's reserved capacity.
func (o GetInferenceGroupStatusResultOutput) BonusExtraCapacity() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GetInferenceGroupStatusResult) *int { return v.BonusExtraCapacity }).(pulumi.IntPtrOutput)
}

// Gets or sets the actual number of endpoints in the group.
func (o GetInferenceGroupStatusResultOutput) EndpointCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GetInferenceGroupStatusResult) *int { return v.EndpointCount }).(pulumi.IntPtrOutput)
}

// Gets or sets the request number of instances for the group.
func (o GetInferenceGroupStatusResultOutput) RequestedCapacity() pulumi.IntPtrOutput {
	return o.ApplyT(func(v GetInferenceGroupStatusResult) *int { return v.RequestedCapacity }).(pulumi.IntPtrOutput)
}

func init() {
	pulumi.RegisterOutputType(GetInferenceGroupStatusResultOutput{})
}
